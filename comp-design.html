<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Kate Izsak — Computational Image Design</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="css/style.css?v=1" />
</head>

<body class="page-gallery">
  <header class="page-header">
 <h1 class="header-anta-neon">Computational Image Design</h1>
    <nav class="nav-bar">
      <a href="index.html" class="nav-btn">Home</a>
      <a href="digital-painting.html" class="nav-btn">Digital Painting</a>
      <a href="comp-design.html" class="nav-btn">Computational Image Design</a>
      <a href="graphic-design.html" class="nav-btn">Graphic Design</a>
      <a href="about-me.html" class="nav-btn">About Me</a>
    </nav>
  </header>

  <main class="gallery-wrap">
    <section class="gallery-grid" aria-label="Gallery">

      <!-- CARD 1 -->
<article class="gallery-card">

  <a
    class="gallery-thumb"
    href="https://raw.githubusercontent.com/kizsak/Portfolio/main/BeeOrchidPolaroid.png"
    target="_blank"
    rel="noopener"
    aria-label="Open full image: Simulated Polaroid"
  >
    <img
      src="https://raw.githubusercontent.com/kizsak/Portfolio/main/BeeOrchidPolaroid.png"
      alt="A digital image showing a simulated, aged and worn Polaroid of a botanical subject"
      loading="lazy"
    >
  </a>

  <div class="gallery-info">
    <h3>Simulated Polaroid</h3>
    <p class="meta">Digital image, 2026</p>
  </div>

  <button class="process-btn" type="button" data-process="process-polaroid">
    View Process
  </button>
</article>

  <!-- CARD 2 -->
<article class="gallery-card">

  <a
    class="gallery-thumb"
    href="https://github.com/kizsak/Portfolio/raw/main/Daguerreotype.jpg"
    target="_blank"
    rel="noopener"
    aria-label="Open full image: Simulated Daguerreotype"
  >
    <img
      src="https://github.com/kizsak/Portfolio/raw/main/Daguerreotype.jpg"
      alt="A digital image showing a simulated, aged and worn Daguerreotype of a 
      botanical subject"
      loading="lazy"
    >
  </a>

  <div class="gallery-info">
    <h3>Simulated Daguerreotype</h3>
    <p class="meta">Digital image, 2025</p>
  </div>

  <button class="process-btn" type="button" data-process="process-heat">
    View Process
  </button>
</article>
      
    <!-- CARD 3 -->
<article class="gallery-card">

  <a
    class="gallery-thumb"
    href="https://github.com/kizsak/Portfolio/raw/main/HeatMapSelfie2.jpg"
    target="_blank"
    rel="noopener"
    aria-label="Open full image: Heat Map Polaroid"
  >
    <img
      src="https://github.com/kizsak/Portfolio/raw/main/HeatMapSelfie2.jpg"
      alt="An image of a woman rendered in purple, orange, and yellow"
      loading="lazy"
    >
  </a>

  <div class="gallery-info">
    <h3>Simulated Heat Map Self Portrait</h3>
    <p class="meta">Digital image, 2025</p>
  </div>

  <button class="process-btn" type="button" data-process="process-heatmap">
    View Process
  </button>
</article>    
      
      
      
      
      <!-- Add more cards... -->

    </section>
  </main>

  <!-- PROCESS MODAL -->
<div class="process-modal" id="process-modal">
  <div class="process-content">
    <span class="process-close">&times;</span>
    <div id="process-body"></div>
  </div>
</div>

<!-- PROCESS CONTENT BLOCKS (hidden) -->
<div class="process-data" id="process-polaroid" hidden>
  <h2>Simulated Polaroid — Process Notes</h2>
<h3>Tools</h3>
  <ul>
    <li><strong>Python</strong>
      <ul>
        <li><strong>Pillow (PIL)</strong> (layout construction, texture layering, compositing)</li>
        <li><strong>random</strong> (stochastic variation)</li>
        <li><strong>argparse</strong> (parameterized output)</li>
      </ul>
    </li>
    <li><strong>Photoshop</strong></li>
    <li><strong>Midjourney</strong></li>
  </ul>
  <p>
    I created a synthetic photograph of an <em>Ophrys apifera</em> (Bee Orchid) in bloom using Midjourney
    (prompt: A photograph of the botanical specimen, bee orchid, photographed in the field in the style of 1980s field
    botany documentation, soft natural light, shallow depth of field, Kodachrome 64 film look, muted warm tones,
    subtle film grain, macro detail, slight fading and color shift.). Then, I created a worn Polaroid frame in Photoshop by layering texture overlays to suggest an aged and worn feel.
    Next, I wrote a Python script
    <a href="https://github.com/kizsak/ImageGenMan/raw/main/PolaroidPython" target="_blank" rel="noopener noreferrer">
      (download)
    </a> to treat the image not as a static photograph but as a material object subject to wear, exposure, and
    chemical instability.
  </p>
</div>

  <div class="process-data" id="process-polaroid" hidden>
  <h2>Simulated Polaroid — Process Notes</h2>
</div>
  
  <div class="process-modal" id="process-modal">
  <div class="process-content">
    <span class="process-close">&times;</span>
    <div id="process-body"></div>
  </div>
</div>

<div class="process-data" id="process-polaroid" hidden>
  <h2>Simulated Polaroid — Process Notes</h2>
    <h3>Tools</h3>
  <ul>
    <li><strong>Python</strong>
      <ul>
        <li><strong>Pillow (PIL)</strong> (layout construction, texture layering, compositing)</li>
        <li><strong>random</strong> (stochastic variation)</li>
        <li><strong>argparse</strong> (parameterized output)</li>
      </ul>
    </li>
    <li><strong>Photoshop</strong></li>
    <li><strong>Midjourney</strong></li>
  </ul>
</div>

  <p>
    I created a synthetic photograph of an <em>Ophrys apifera</em> (Bee Orchid) in bloom using Midjourney
    (prompt: A photograph of the botanical specimen, bee orchid, photographed in the field in the style of 1980s field
    botany documentation, soft natural light, shallow depth of field, Kodachrome 64 film look, muted warm tones,
    subtle film grain, macro detail, slight fading and color shift.). Then, I created a worn Polaroid frame in Photoshop by layering texture overlays to suggest an aged and worn feel.
    Next, I wrote a Python script
    <a href="https://github.com/kizsak/ImageGenMan/raw/main/PolaroidPython" target="_blank" rel="noopener noreferrer">
      (download)
    </a> to treat the image not as a static photograph but as a material object subject to wear, exposure, and
    chemical instability.
  </p>

  <div class="process-data" id="process-daguerreotype" hidden>
  <h2>Simulated Daguerreotype — Process Notes</h2>
     <ul class="tools-list">
          <li><strong>Python</strong>
            <ul>
              <li><strong>NumPy</strong> (pixel-level tonal remapping, metallic color mapping, vignette math)</li>
              <li><strong>Pillow (PIL)</strong> (grayscale conversion, compositing, filters, alpha masks)</li>
              <li><strong>math</strong> (directional sheen and radial calculations)</li>
            </ul>
          </li>
          <li><strong>Photoshop</strong></li>
          <li><strong>Midjourney</strong></li>
        </ul>
  <p>
    I used Midjourney to create a synthetic photograph of an <em>Helenium 
      Autumnale</em> (Sneezeweed) in bloom.  I then processed 
    the image using a Python script 
    <a href="https://github.com/kizsak/ImageGenMan/raw/main/PolaroidPython" target='_blank' rel='noopener noreferrer'>(download)</a> 
    that converts the photograph to grayscale, reshapes its tonal curve, and maps 
    it onto a simulated silver plate surface. The script introduces a series of 
    degradations, including metallic color shifts, directional sheen, vignette 
    falloff, and tarnish artifacts. Finally, it precisely fits the image into an 
    aged and worn digital daguerreotype frame I created in Photoshop, with 
    softened edges and inner shadow to simulate depth and mounting.
 </p>
</div>

  <div class="process-data" id="process-heatmap" hidden>
  <h2>Simulated Heat Map Self Portrait — Process Notes</h2>
     <ul class="tools-list">
          <li><strong>Python</strong>
           <li><strong>Python</strong>
            <ul>
              <li><strong>NumPy</strong> (depth-to-color mapping, numeric normalization)</li>
              <li><strong>Pillow (PIL)</strong> (image I/O and format conversion)</li>
            </ul>
          </li>
          <li><strong>Photoshop</strong></li>
          <li><strong>Midjourney</strong></li>
        </ul></template>
      <template id="desc-slide">
         <strong>Tools:</strong>
        <ul class="tools-list">
          <li><strong>Python</strong>
            <ul>
              <li><strong>Pillow (PIL)</strong> (layout construction, texture layering, compositing)</li>
              <li><strong>random</strong> (stochastic variation)</li>
              <li><strong>argparse</strong> (parameterized output)</li>
            </ul>
          </li>
          <li><strong>Photoshop</strong></li>
          <li><strong>Midjourney</strong></li>

        </ul>
  <p>
          I began with a photographic self-portrait. I used Photoshop to construct a depth map of the image by manually segmenting the image into spatial regions using selection tools and tonal adjustments. I then processed this depth map with a Python script <a href="https://github.com/kizsak/ImageGenMan/raw/main/PolaroidPython" target='_blank' rel='noopener noreferrer'>(download)</a> that reads pixel-level depth values and remaps them to a false-color heat visualization. 
</p>

  
  
  <script src="js/process-modal.js"></script>
</body>
</html>










