<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Kate Izsak - Digital and Computational Arts</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <!-- Main site stylesheet -->
  <link rel="stylesheet" href="css/style.css">
  <body class="page-IF">

  <!-- Top Neon Title -->
  <header class="page-header">
    <h1 class="neon">Computational Image Design</h1>
    <nav class="nav-bar">
      <a href="index.html" class="nav-btn">Home</a>
      <a href="digital-painting.html" class="nav-btn">Digital Painting</a>
      <a href="graphic-design.html" class="nav-btn">Graphic Design</a>
      <a href="if.html" class="nav-btn">Interactive Fiction</a>
      <a href="about-me.html" class="nav-btn">About Me</a>
    </nav>
  </header>

  <main class="gallery-layout">

    <!-- LEFT: title + description -->
    <section class="gallery-info">
      <h2 id="image-caption" class="neon-soft"></h2>
      <div id="image-description" class="piece-description"></div>
    </section>

    <!-- RIGHT: carousel -->
    <section class="gallery-carousel">

      <div class="carousel-window">
        <img
          src="https://github.com/kizsak/Portfolio/raw/main/BeeOrchidPolaroid.png"
          data-full="https://github.com/kizsak/Portfolio/raw/main/BeeOrchidPolaroid.png"
          alt="An image of a worn Polaroid of a bee orchid in bloom"
          class="carousel-image active"
          data-caption="<em>Aged Polaroid</em>"
          data-desc="desc-polaroid"
        >

        <img
          src="https://github.com/kizsak/Portfolio/raw/main/Daguerreotype.jpg"
          data-full="https://github.com/kizsak/Portfolio/raw/main/Daguerreotype.jpg"
          alt="An image of an aged Daguerreotype-style botanical photograph"
          class="carousel-image"
          data-caption="<em>Daguerreotype</em>"
          data-desc="desc-daguerreotype"
        >

        <img
          src="https://github.com/kizsak/Portfolio/raw/main/HeatMapSelfie2.jpg"
          data-full="https://github.com/kizsak/Portfolio/raw/main/HeatMapSelfie2.jpg"
          alt="An image of a woman rendered in purple, orange, and yellow"
          class="carousel-image"
          data-caption="<em>False-Color Heat Map Portrait</em>"
          data-desc="desc-heatmap"
        >
      
      <img
  src="https://github.com/kizsak/Portfolio/raw/main/35mmslide.jpg"
  data-full="https://github.com/kizsak/Portfolio/raw/main/35mmslide.jpg"
  alt="An image of a 35mm slide showing a photograph of a field of black-eyed susans)"
  class="carousel-image"
  data-caption="<em>35mm Slide</em>"
  data-desc="desc-slide"
>

<img
  src="https://github.com/kizsak/Portfolio/raw/main/ComicBook.jpg"
  data-full="https://github.com/kizsak/Portfolio/raw/main/ComicBook.jpg"
  alt="Write an accessible description of the image"
  class="carousel-image"
  data-caption="<em>Comic Book Sketch</em>"
  data-desc="desc-comic"
>

<img
  src="https://github.com/kizsak/Portfolio/raw/main/Microfiche.jpg"
  data-full="https://github.com/kizsak/Portfolio/raw/main/Microfiche.jpg"
  alt="A cyanotype of a gardenia"
  class="carousel-image"
  data-caption="<em>Cyanotype</em>"
  data-desc="desc-cyan"
>

<img
  src="https://github.com/kizsak/Portfolio/raw/main/Microfiche.jpg"
  data-full="https://github.com/kizsak/Portfolio/raw/main/Microfiche.jpg"
  alt="Write an accessible description of the image"
  class="carousel-image"
  data-caption="<em>Microfiche Film</em>"
  data-desc="desc-micro"
>

<img
  src="https://github.com/kizsak/Portfolio/raw/main/PencilDrawing.jpg"
  data-full="https://github.com/kizsak/Portfolio/raw/main/PencilDrawing.jpg"
  alt="A cyanotype of a gardenia"
  class="carousel-image"
  data-caption="<em>Pencil Drawing</em>"
  data-desc="desc-pencil”
>
  
<img
  src="https://github.com/kizsak/Portfolio/raw/main/FILE.png"
  data-full="https://github.com/kizsak/Portfolio/raw/main/FILE.png"
  alt="Write an accessible description of the image"
  class="carousel-image"
  data-caption="<em>Chemical Bath Reveal</em>"
  data-desc="desc-chem"
>

<img
  src="https://github.com/kizsak/Portfolio/raw/main/FILE.png"
  data-full="https://github.com/kizsak/Portfolio/raw/main/FILE.png"
  alt="Write an accessible description of the image"
  class="carousel-image"
  data-caption="<em>Glitch Recover</em>"
  data-desc="desc-glitch"
>
      </div>

      <!-- Controls (you were missing these in the current version) -->
      <div class="carousel-controls">
        <button class="carousel-btn prev" type="button" aria-label="Previous image">‹</button>
        <button class="carousel-btn next" type="button" aria-label="Next image">›</button>
      </div>

      <!-- Description Templates -->
      <template id="desc-polaroid">
        <strong>Tools:</strong>
        <ul class="tools-list">
          <li><strong>Python</strong>
            <ul>
              <li><strong>Pillow (PIL)</strong>
                <ul>
                  <li>image compositing</li>
                  <li>resizing</li>
                  <li>masking</li>
                  <li>blend operations</li>
                </ul>
              </li>
              <li><strong>argparse</strong> (command-line parameter control)</li>
              <li><strong>pathlib</strong> (file and folder management)</li>
              <li><strong>random</strong> (controlled variation in frame and overlay selection)</li>
            </ul>
          </li>
          <li><strong>Midjourney</strong></li>
          <li><strong>Photoshop</strong></li>
        </ul>

        <p>
          I created a synthetic photograph of an <em>Ophrys apifera</em> (Bee Orchid) in bloom using Midjourney. Then, I created a worn Polaroid frame in Photoshop by layering texture overlays to suggest an aged and worn feel. Next, I wrote a Python script
          <a href="https://github.com/kizsak/ImageGenMan/raw/main/PolaroidPython" target="_blank" rel="noopener noreferrer">(download)</a>.
          This script treats the image not as a static photograph but as a material object subject to wear, exposure, and chemical instability. Starting from a clean digital input, the script introduces a series of degradations—edge softening, tonal flattening, color drift, and localized light leaks—that echo the visual artifacts of aging instant film. Rather than applying a single filter, the process unfolds in stages, allowing each transformation to subtly interfere with the last.
        </p>

        <p>
          I created a series of these images to serve as epistolary sources for an interactive fiction game.
        </p>
      </template>

      <template id="desc-daguerreotype">
        <strong>Tools:</strong>
        <ul class="tools-list">
          <li><strong>Python</strong>
            <ul>
              <li><strong>NumPy</strong> (pixel-level tonal remapping, metallic color mapping, vignette math)</li>
              <li><strong>Pillow (PIL)</strong> (grayscale conversion, compositing, filters, alpha masks)</li>
              <li><strong>math</strong> (directional sheen and radial calculations)</li>
            </ul>
          </li>
          <li><strong>Photoshop</strong></li>
          <li><strong>Midjourney</strong></li>
        </ul>

        <p>
          I used Midjourney to create a synthetic photograph of an <em>Ophrys apifera</em> (Bee Orchid) in bloom. I then processed the image using a Python script
          <a href="https://github.com/kizsak/ImageGenMan/raw/main/PolaroidPython" target="_blank" rel="noopener noreferrer">(download)</a>
          that converts the photograph to grayscale, reshapes its tonal curve, and maps it onto a simulated silver plate surface. The script introduces metallic color shifts, directional sheen, vignette falloff, and tarnish artifacts.
        </p>

        <p>
          Finally, it precisely fits the image into an aged and worn digital daguerreotype frame I created in Photoshop, with softened edges and inner shadow to simulate depth and mounting.
        </p>
      </template>

      <template id="desc-heatmap">
        <strong>Tools:</strong>
        <ul class="tools-list">
          <li><strong>Python</strong>
            <ul>
              <li><strong>NumPy</strong> (depth-to-color mapping, numeric normalization)</li>
              <li><strong>Pillow (PIL)</strong> (image I/O and format conversion)</li>
            </ul>
          </li>
          <li><strong>Photoshop</strong></li>
          <li><strong>Midjourney</strong></li>
        </ul>

        <p>
          I began with a photographic self-portrait. I used Photoshop to construct a depth map of the image by manually segmenting the image into spatial regions using selection tools and tonal adjustments. I then processed the depth map with a Python script
          <a href="https://github.com/kizsak/ImageGenMan/raw/main/PolaroidPython" target="_blank" rel="noopener noreferrer">(download)</a>
          that reads pixel-level depth values and remaps them to a false-color heat visualization.
        </p>
      </template>

      <template id="desc-slide">
  <strong>Tools:</strong>
  <ul class="tools-list">
    <li><strong>Python</strong>
      <ul>
        <li><strong>Pillow (PIL)</strong> ((layout construction, texture layering, compositing)</li>
        <li><strong>random</strong> (stochastic wash variation)</li>
        <li><strong>argparse</strong> (parameterized output)</li>      
        <li><strong>random</strong> (structured output handling)</li>
</ul>
    </li>
    <li><strong>Photoshop</strong></li>
    <li><strong>Midjourney</strong></li>
  </ul>

  <p>I took a photograph of my husband. I then processed the image with a Python script <a href="https://github.com/kizsak/ImageGenMan/raw/main/PolaroidPython" target='_blank' rel='noopener noreferrer'>(download)</a> to reduce the color palette using k-means clustering, extract bold inked edges using edge detection, and overlay halftone dot patterns to mimic printed comic panels. The script also adds borders, captions, and optional speech bubbles to complete the panel structure.
  </p>
</template>

<template id="desc-comic">
  <strong>Tools:</strong>
  <ul class="tools-list">
    <li><strong>Python</strong>
      <ul>
        <li><strong>Pillow (PIL)</strong> ((layout construction, texture layering, compositing)</li>
        <li><strong>random</strong> (stochastic wash variation)</li>
        <li><strong>argparse</strong> (parameterized output)</li>      
        <li><strong>random</strong> (structured output handling)</li>
</ul>
    </li>
    <li><strong>Photoshop</strong></li>
    <li><strong>Midjourney</strong></li>
  </ul>

  <p>
  </p>
</template>

<template id="desc-cyan">
  <strong>Tools:</strong>
<ul>
    <li><strong>Python</strong>
      <ul>
        <li><strong>Pillow (PIL)</strong> (grayscale conversion, color mapping, blur)</li>
        <li><strong>NumPy</strong> (procedural wash mask generation)</li>
        <li><strong>random</strong> (stochastic wash variation)</li>
</ul>
    </li>
    <li><strong>Photoshop</strong></li>
    <li><strong>Midjourney</strong></li>
  </ul>
  <p>
    I used Midjourney to create a synthetic photograph of a Gardenia jasminoides  (Gardenia). (Prompt: A photograph of the botanical specimen, gardenia, photographed in the field in the style of 1980s field botany documentation, soft natural light, shallow depth of field, Kodachrome 64 film look, muted warm tones, subtle film grain, macro detail, slight fading and color shift. The photograph should show the sculptural details of the petals well.) I then processed the image with a Python script <a href="https://github.com/kizsak/ImageGenMan/raw/main/PolaroidPython" target='_blank' rel='noopener noreferrer'>(download)</a> to remap tonal values into a cyanotype-inspired blue color range and layered a procedurally generated wash mask to simulate uneven chemical absorption. The image was also softened slightly to evoke paper texture and hand-coated surfaces.
  </p>
</template>

<template id="desc-micro">
  <strong>Tools:</strong>
<ul>
    <li><strong>Python</strong>
      <ul>
        <li><strong>Pillow (PIL)</strong> (grid layout, typography, compositing)</li>
        <li><strong>NumPy</strong> (procedural wash mask generation)</li>
        <li><strong>random</strong> (subtle noise and grain)</li>
        <li><strong>argparse</strong> (subtle noise and grain)</li>
        <li><strong>pathlib</strong> (file structure handling)</li>
        <li><strong>datetime</strong> (archival metadata)</li>
</ul>
    <li><strong>Photoshop</strong></li>
    <li><strong>Midjourney</strong></li>
  </ul>
<p>I created a synthetic photographic image using Midjourney. I then used a Python script <a href="https://github.com/kizsak/ImageGenMan/raw/main/PolaroidPython" target='_blank' rel='noopener noreferrer'>(download)</a> to fragment, scale, and tile the image into a grid structure modeled after microfiche archival formats. Final compositional and tonal adjustments were made in Photoshop to emphasize the aesthetics of compression and institutional storage.
  </p>
</template>

<template id="desc-pencil">
  <strong>Tools:</strong>
  <ul class="tools-list">
    <li><strong>Python</strong>
      <ul>
        <li><strong>Pillow (PIL)</strong> ((layout construction, texture layering, compositing)</li>
        <li><strong>random</strong> (stochastic wash variation)</li>
        <li><strong>argparse</strong> (parameterized output)</li>      
        <li><strong>random</strong> (structured output handling)</li>
</ul>
    </li>
    <li><strong>Photoshop</strong></li>
    <li><strong>Midjourney</strong></li>
  </ul>
  <p>I took a photograph of a yellow-bellied sapsucker on a Scotch Pine. I then processed the image using a Python script <a href="https://github.com/kizsak/ImageGenMan/raw/main/PolaroidPython" target='_blank' rel='noopener noreferrer'>(download)</a>that converts it to grayscale, applies Gaussian blur, and uses a dodge-blend technique to simulate graphite shading. A secondary edge-based output produces a crisp line-drawing variant. 
  </p>
</template>

<template id="desc-chem”>
  <strong>Tools:</strong>
  <ul class="tools-list">
    <li><strong>Python</strong>
      <ul>
        <li><strong>Pillow (PIL)</strong> ((layout construction, texture layering, compositing)</li>
        <li><strong>random</strong> (stochastic wash variation)</li>
        <li><strong>argparse</strong> (parameterized output)</li>      
        <li><strong>random</strong> (structured output handling)</li>
</ul>
    </li>
    <li><strong>Photoshop</strong></li>
    <li><strong>Midjourney</strong></li>
  </ul>
  <p>
    I used Midjourney to create a synthetic photographic image of a field of <em>Rudbeckia hirta</em> (Black-Eyed Susans). I then processed the image with a Python script <a href="https://github.com/kizsak/ImageGenMan/raw/main/PolaroidPython" target='_blank' rel='noopener noreferrer'>(download)</a> that animates the gradual emergence of the image using layered noise fields, threshold masks, bloom effects, and evolving color casts that simulate photographic development in a chemical bath. Each frame reveals additional image detail until the photograph fully resolves.
  </p>
</template>

<template id="desc-glitch”>
  <strong>Tools:</strong>
  <ul class="tools-list">
    <li><strong>Python</strong>
      <ul>
        <li><strong>NumPy</strong> (noise fields, masks, temporal interpolation)</li>
        <li><strong>Pillow (PIL)</strong> (frame-by-frame image processing)</li>                  
        <li><strong>imageio</strong> (GIF / MP4 generation)</li>      
        <li><strong>argparse</strong> (timing, resolution, and style controls)</li>      
        <li><strong>random</strong> (stochastic animation variation)</li>
    </ul>
    <li><strong>Photoshop</strong></li>
    <li><strong>Midjourney</strong></li>
  </ul>
  <p>
    I used Midjourney to create a synthetic photographic image of a field of <em>Rudbeckia hirta</em> (Black-Eyed Susans). I then processed the image with a Python script <a href="https://github.com/kizsak/ImageGenMan/raw/main/PolaroidPython" target='_blank' rel='noopener noreferrer'>(download)</a> to deliberately corrupt the image using channel misalignment, scanlines, noise-driven tearing, and glitch artifacts before gradually stabilizing the image over time. 
  </p>
</template>
    </section>
  </main>

  <!-- LIGHTBOX -->
  <div class="lightbox" id="lightbox" aria-hidden="true">
    <div class="lightbox-backdrop" data-close></div>

    <figure class="lightbox-content" role="dialog" aria-modal="true" aria-label="Image viewer">
      <button class="lightbox-close" type="button" data-close aria-label="Close">×</button>
      <img class="lightbox-img" id="lightboxImg" alt="">
      <figcaption class="lightbox-caption" id="lightboxCaption"></figcaption>
    </figure>
  </div>

  <!-- JS -->
  <script>
    (function () {
      const images = document.querySelectorAll('.carousel-image');
      const prevBtn = document.querySelector('.carousel-btn.prev');
      const nextBtn = document.querySelector('.carousel-btn.next');
      const captionEl = document.getElementById('image-caption');
      const descriptionEl = document.getElementById('image-description');

      const lightbox = document.getElementById('lightbox');
      const lightboxImg = document.getElementById('lightboxImg');
      const lightboxCaption = document.getElementById('lightboxCaption');

      if (!images.length) return;

      let current = 0;

      function getDescHTML(img) {
        const tplId = img.dataset.desc;
        const tpl = tplId ? document.getElementById(tplId) : null;
        return tpl ? tpl.innerHTML : '';
      }

      function updateText(index) {
        const img = images[index];
        captionEl.innerHTML = img.dataset.caption || '';
        descriptionEl.innerHTML = getDescHTML(img);
      }

      function showSlide(index) {
        images[current].classList.remove('active');
        current = (index + images.length) % images.length;
        images[current].classList.add('active');
        updateText(current);
      }

      function openLightbox(img) {
        const full = img.dataset.full || img.src;
        lightboxImg.src = full;
        lightboxImg.alt = img.alt || '';
        lightboxCaption.innerHTML = (img.dataset.caption || '') + '<br>' + getDescHTML(img);

        lightbox.classList.add('is-open');
        lightbox.setAttribute('aria-hidden', 'false');
        document.body.style.overflow = 'hidden';
      }

      function closeLightbox() {
        lightbox.classList.remove('is-open');
        lightbox.setAttribute('aria-hidden', 'true');
        document.body.style.overflow = '';
      }

      // Init
      images[0].classList.add('active');
      updateText(0);

      prevBtn?.addEventListener('click', () => showSlide(current - 1));
      nextBtn?.addEventListener('click', () => showSlide(current + 1));

      images.forEach(img => {
        img.style.cursor = 'zoom-in';
        img.addEventListener('click', () => openLightbox(img));
      });

      lightbox?.addEventListener('click', e => {
        if (e.target.hasAttribute('data-close')) closeLightbox();
      });

      document.addEventListener('keydown', e => {
        if (e.key === 'Escape') closeLightbox();
      });
    })();
  </script>

</body>
</html>
